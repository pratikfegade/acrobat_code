#[version = "0.0.5"]

def @rnn(
  %inputs: List[Tensor[(1, 256), float32]],
  %state: Tensor[(1, 256), float32],

  %weight: Tensor[(256, 512), float32],
  %bias: Tensor[(1, 256), float32]
) -> List[Tensor[(1, 256), float32]] {
  match?(%inputs) {
    Nil => Nil,
    Cons(%input, %tail) => {
      let %func = fn(
        %_input: Tensor[(1, 256), float32],
        %_state: Tensor[(1, 256), float32],
        %_weight: Tensor[(256, 512), float32],
        %_bias: Tensor[(1, 256), float32],
        Primitive = 1
      ) {
        sigmoid(
          %_bias + nn.dense(concatenate((%_input, %_state), axis=1), %_weight, units=256)
        )
      };
      let %new_state = %func(%input, %state, %weight, %bias);
      Cons(%new_state, @rnn(%tail, %new_state, %weight, %bias))
    }
  }
}

def @get_classification_fn (
  %_weight: Tensor[(16, 512), float32],
  %_bias: Tensor[(1, 16), float32],
) {
  fn(
    %_fbinputs: (Tensor[(1, 256), float32], Tensor[(1, 256), float32])
  ) {
    argmax(
      %_bias + nn.dense(concatenate((%_fbinputs.0, %_fbinputs.1), axis=1), %_weight, units=16)
    )
  }
}

def @get_argmax_fn () {
  fn(
    %_fbinputs: Tensor[(1, 16), float32]
  ) {
    argmax(%_fbinputs)
  }
}

def @revl[A](%xs: List[A], %acc: List[A]) -> List[A] {
  match?(%xs) {
    Cons(%h, %t) => @revl(%t, Cons(%h, %acc)),
    Nil => %acc,
  }
}

def @tuple_map_rnn(
  %f_rnn_weight: Tensor[(256, 512), float32],
  %f_rnn_bias: Tensor[(1, 256), float32],
  %f_rnn_init: Tensor[(1, 256), float32],

  %b_rnn_weight: Tensor[(256, 512), float32],
  %b_rnn_bias: Tensor[(1, 256), float32],
  %b_rnn_init: Tensor[(1, 256), float32],

  %f_inputs: List[Tensor[(1, 256), float32]],
  %b_inputs: List[Tensor[(1, 256), float32]],
) -> (List[Tensor[(1, 256), float32]], List[Tensor[(1, 256), float32]]) {
  let %f_res = @rnn(%f_inputs, %f_rnn_init, %f_rnn_weight, %f_rnn_bias);
  let %b_res_rev = @rnn(%b_inputs, %b_rnn_init, %b_rnn_weight, %b_rnn_bias);
  (%f_res, %b_res_rev)
}

def @main(
  %f_rnn_weight: Tensor[(256, 512), float32],
  %f_rnn_bias: Tensor[(1, 256), float32],
  %f_rnn_init: Tensor[(1, 256), float32],

  %b_rnn_weight: Tensor[(256, 512), float32],
  %b_rnn_bias: Tensor[(1, 256), float32],
  %b_rnn_init: Tensor[(1, 256), float32],

  %cweight: Tensor[(16, 512), float32],
  %cbias: Tensor[(1, 16), float32],

  %f_inputs: List[Tensor[(1, 256), float32]]
) {
  let %b_inputs = @revl(%f_inputs, Nil);
  let %fb_res = @tuple_map_rnn(
    %f_rnn_weight, %f_rnn_bias, %f_rnn_init,
    %b_rnn_weight, %b_rnn_bias, %b_rnn_init,
    %f_inputs, %b_inputs,
  );

  let %f_res = %fb_res.0;
  let %b_res = @revl(%fb_res.1, Nil);

  let %_ = db.phase_change();

  // let %combined = @zip(%f_res, %b_res);
  // let %class_scores = @map(@get_classification_fn(%cweight, %cbias), %combined);
  // let %classes = @map(@get_argmax_fn(), %class_scores);
  // (@zip(%combined, %class_scores), %classes)

  let %combined = @zip(%f_res, %b_res);
  let %classes = @map(@get_classification_fn(%cweight, %cbias), %combined);
  %classes
}
