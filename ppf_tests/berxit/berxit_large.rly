#[version = "0.0.5"]

def @transformer_encoder(
  %prelinear_wq: Tensor[(1024, 1024), float32],
  %prelinear_wk: Tensor[(1024, 1024), float32],
  %prelinear_wv: Tensor[(1024, 1024), float32],

  %prelinear_bq: Tensor[(1, 1024), float32],
  %prelinear_bk: Tensor[(1, 1024), float32],
  %prelinear_bv: Tensor[(1, 1024), float32],

  %ln1_g: Tensor[(1024), float32],
  %ln1_b: Tensor[(1024), float32],

  %postlinear_w: Tensor[(1024, 1024), float32],
  %postlinear_b: Tensor[(1, 1024), float32],

  %ff1_w: Tensor[(4096, 1024), float32],
  %ff1_b: Tensor[(1, 4096), float32],

  %ff2_w: Tensor[(1024, 4096), float32],
  %ff2_b: Tensor[(1, 1024), float32],

  %ln2_g: Tensor[(1024), float32],
  %ln2_b: Tensor[(1024), float32],

  %input: Tensor[(128, 1024), float32],
) -> Tensor[(128, 1024), float32] {

  let %qkv_prelinear_func = fn(
    %_input: Tensor[(128, 1024), float32],
    %_weight: Tensor[(1024, 1024), float32],
    %_bias: Tensor[(1, 1024), float32],
    Primitive=1
  ) -> Tensor[(16, 128, 64), float32] {
    transpose(
      reshape(
        nn.dense(%_input, %_weight, units = 1024) + %_bias,
        newshape=[128, 16, 64]
      ),
      axes=[1, 0, 2]
    )
  };

  let %q = %qkv_prelinear_func(%input, %prelinear_wq, %prelinear_bq);
  let %k = %qkv_prelinear_func(%input, %prelinear_wk, %prelinear_bk);
  let %v = %qkv_prelinear_func(%input, %prelinear_wv, %prelinear_bv);

  let %qkt = nn.softmax(nn.batch_matmul(%q, %k, transpose_a=False, transpose_b=True));

  let %attn_v_func = fn(
    %_qkt: Tensor[(16, 128, 128), float32],
    %_v: Tensor[(16, 128, 64), float32],
    Primitive=1
  ) {
    reshape(
      transpose(
        nn.batch_matmul(%_qkt, %_v, transpose_a=False, transpose_b=False),
        axes=[1, 0, 2]
      ),
      newshape=[128, 1024]
    )
  };

  let %attn_v = %attn_v_func(%qkt, %v);
  let %post_linear = nn.dense(%attn_v, %postlinear_w, units=1024) + %postlinear_b + %input;
  let %layer_normed = nn.layer_norm(%post_linear, %ln1_g, %ln1_b);
  let %ff1 = nn.relu(nn.dense(%layer_normed, %ff1_w, units=4096) + %ff1_b);
  let %ff2 = nn.dense(%ff1, %ff2_w, units=1024) + %ff2_b + %post_linear;
  let %out = nn.layer_norm(%ff2, %ln2_g, %ln2_b);
  %out
}

def @bertxit(
  %input: Tensor[(128, 1024), float32],

  %execution_ctr: Tensor[(), int32SS],
  %num_layers: Tensor[(), int32SS],

  %prelinear_wq: Tensor[(1024, 1024), float32],
  %prelinear_wk: Tensor[(1024, 1024), float32],
  %prelinear_wv: Tensor[(1024, 1024), float32],
  %prelinear_bq: Tensor[(1, 1024), float32],
  %prelinear_bk: Tensor[(1, 1024), float32],
  %prelinear_bv: Tensor[(1, 1024), float32],
  %ln1_g: Tensor[(1024), float32],
  %ln1_b: Tensor[(1024), float32],
  %postlinear_w: Tensor[(1024, 1024), float32],
  %postlinear_b: Tensor[(1, 1024), float32],
  %ff1_w: Tensor[(4096, 1024), float32],
  %ff1_b: Tensor[(1, 4096), float32],
  %ff2_w: Tensor[(1024, 4096), float32],
  %ff2_b: Tensor[(1, 1024), float32],
  %ln2_g: Tensor[(1024), float32],
  %ln2_b: Tensor[(1024), float32],
  %certainty_w: Tensor[(1, 1024), float32],
  %certainty_b: Tensor[(1, 1), float32],

  %dummy: Tensor[(1, 1), float32],
) -> Tensor[(128, 1024), float32] {

  let %certainty_fn = fn (
    %_input: Tensor[(128, 1024), float32],
    %_weight: Tensor[(1, 1024), float32],
    %_bias: Tensor[(1, 1), float32],
    Primitive=1
  ) -> Tensor[(1, 1), float32] {
    nn.dense(reshape(take(%_input, 0, axis=0, mode="fast"), newshape=[1, 1024]), %_weight, units=1) + %_bias
  };

  let %layer_out = @transformer_encoder(
    %prelinear_wq, %prelinear_wk, %prelinear_wv,
    %prelinear_bq, %prelinear_bk, %prelinear_bv,
    %ln1_g, %ln1_b,
    %postlinear_w, %postlinear_b,
    %ff1_w, %ff1_b,
    %ff2_w, %ff2_b,
    %ln2_g, %ln2_b,
    %input
  );

  let %confidence = %certainty_fn(%layer_out, %certainty_w, %certainty_b);
  let %to_exit = random.db_uniform(0, %num_layers - %execution_ctr, out_shape=[], out_dtype="int32");
  let %exit_cond = %to_exit > 0;
  let %layer_cond = %execution_ctr <= %num_layers;
  if (logical_and(%exit_cond, %layer_cond)) {
    @bertxit(
      %layer_out,
      %execution_ctr + 1, %num_layers,
      %prelinear_wq, %prelinear_wk, %prelinear_wv,
      %prelinear_bq, %prelinear_bk, %prelinear_bv,
      %ln1_g, %ln1_b,
      %postlinear_w, %postlinear_b,
      %ff1_w, %ff1_b,
      %ff2_w, %ff2_b,
      %ln2_g, %ln2_b,
      %certainty_w, %certainty_b,
      %confidence
    )
  } else {
    %layer_out
  }
}


def @classifier(
  %classification_w: Tensor[(16, 1024), float32],
  %classification_b: Tensor[(1, 16), float32]
  %bert_out: Tensor[(128, 1024), float32],
) -> Tensor[(), int32] {
  let %classification_fn = fn (
    %_input: Tensor[(128, 1024), float32],
    %_weight: Tensor[(16, 1024), float32],
    %_bias: Tensor[(1, 16), float32],
    Primitive=1
  ) -> Tensor[(1, 16), float32] {
    nn.dense(reshape(take(%_input, 0, axis=0, mode="fast"), newshape=[1, 1024]), %_weight, units=16) + %_bias
  };

  argmax(nn.softmax(%classification_fn(%bert_out, %classification_w, %classification_b)))
}

def @main(
  %prelinear_wq: Tensor[(1024, 1024), float32],
  %prelinear_wk: Tensor[(1024, 1024), float32],
  %prelinear_wv: Tensor[(1024, 1024), float32],
  %prelinear_bq: Tensor[(1, 1024), float32],
  %prelinear_bk: Tensor[(1, 1024), float32],
  %prelinear_bv: Tensor[(1, 1024), float32],
  %ln1_g: Tensor[(1024), float32],
  %ln1_b: Tensor[(1024), float32],
  %postlinear_w: Tensor[(1024, 1024), float32],
  %postlinear_b: Tensor[(1, 1024), float32],
  %ff1_w: Tensor[(4096, 1024), float32],
  %ff1_b: Tensor[(1, 4096), float32],
  %ff2_w: Tensor[(1024, 4096), float32],
  %ff2_b: Tensor[(1, 1024), float32],
  %ln2_g: Tensor[(1024), float32],
  %ln2_b: Tensor[(1024), float32],
  %certainty_w: Tensor[(1, 1024), float32],
  %certainty_b: Tensor[(1, 1), float32],
  %classification_w: Tensor[(16, 1024), float32],
  %classification_b: Tensor[(1, 16), float32]

  %input: Tensor[(128, 1024), float32]
) -> Tensor[(), int32] {
  let %bert_out = @bertxit(
    %input,
    0, 6,
    %prelinear_wq, %prelinear_wk, %prelinear_wv,
    %prelinear_bq, %prelinear_bk, %prelinear_bv,
    %ln1_g, %ln1_b,
    %postlinear_w, %postlinear_b,
    %ff1_w, %ff1_b,
    %ff2_w, %ff2_b,
    %ln2_g, %ln2_b,
    %certainty_w, %certainty_b,
    reshape(0f, newshape=[1,1]),
  );

  let %_ = db.phase_change();

  @classifier(%classification_w, %classification_b, %bert_out)
}
